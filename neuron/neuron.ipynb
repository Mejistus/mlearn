{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 一室之不治，何以家国天下为？\n",
    "> 从最简单的样例开始利用神经网络\n",
    "> 构建个模\n",
    "\n",
    "## 神经网络的原理\n",
    "\n",
    "神经网络是一种模仿人脑神经元结构的计算模型，用于处理复杂的数据模式和关系。以下是神经网络的基本原理和构成要素。\n",
    "\n",
    "### 神经元\n",
    "\n",
    "神经网络的基本单位是神经元，神经元接收输入信号，通过加权求和和激活函数产生输出。一个神经元的数学表示为：\n",
    "\n",
    "$$\n",
    "y = f\\left( \\sum_{i=1}^{n} w_i x_i + b \\right)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- \\( x_i \\) 是输入信号\n",
    "- \\( w_i \\) 是权重\n",
    "- \\( b \\) 是偏置\n",
    "- \\( f \\) 是激活函数\n",
    "\n",
    "### 激活函数\n",
    "\n",
    "激活函数用于引入非线性，常见的激活函数有：\n",
    "\n",
    "- Sigmoid 函数：\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "- ReLU 函数：\n",
    "\n",
    "$$\n",
    "f(x) = \\max(0, x)\n",
    "$$\n",
    "\n",
    "- Tanh 函数：\n",
    "\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "### 网络结构\n",
    "\n",
    "神经网络通常由多个层组成，包括输入层、隐藏层和输出层。每层由多个神经元组成。\n",
    "\n",
    "#### 输入层\n",
    "\n",
    "输入层接收外部输入数据，不进行任何计算，直接传递到下一层。\n",
    "\n",
    "#### 隐藏层\n",
    "\n",
    "隐藏层位于输入层和输出层之间，可以有一层或多层。每个隐藏层神经元接收前一层的输出，进行加权求和和激活。\n",
    "\n",
    "#### 输出层\n",
    "\n",
    "输出层产生最终的输出结果，其结构和神经元数量取决于具体任务。\n",
    "\n",
    "### 前向传播\n",
    "\n",
    "前向传播是指从输入层开始，逐层计算每个神经元的输出，直到输出层。每层的输出作为下一层的输入。\n",
    "\n",
    "### 误差计算\n",
    "\n",
    "在训练过程中，通过损失函数计算预测输出与真实值之间的误差。常用的损失函数有均方误差和交叉熵损失。\n",
    "\n",
    "- 均方误差（MSE）：\n",
    "\n",
    "$$\n",
    "E = \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "- 交叉熵损失：\n",
    "\n",
    "$$\n",
    "E = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "### 反向传播\n",
    "\n",
    "反向传播用于更新神经网络的权重和偏置，以最小化损失函数。反向传播通过链式法则计算梯度，并使用优化算法（如梯度下降）进行参数更新。\n",
    "\n",
    "#### 梯度下降\n",
    "\n",
    "梯度下降通过以下公式更新权重和偏置：\n",
    "\n",
    "$$\n",
    "w_i = w_i - \\eta \\frac{\\partial E}{\\partial w_i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\eta \\frac{\\partial E}{\\partial b}\n",
    "$$\n",
    "\n",
    "其中 \\( \\eta \\) 是学习率。\n",
    "\n",
    "### 训练过程\n",
    "\n",
    "神经网络的训练过程包括以下步骤：\n",
    "\n",
    "1. 初始化权重和偏置。\n",
    "2. 进行前向传播计算输出。\n",
    "3. 计算损失函数值。\n",
    "4. 进行反向传播计算梯度。\n",
    "5. 更新权重和偏置。\n",
    "6. 重复以上步骤，直到损失函数收敛或达到预定的训练次数。\n",
    "\n",
    "通过这些步骤，神经网络能够逐渐优化其参数，提高对复杂模式和数据关系的建模能力。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
